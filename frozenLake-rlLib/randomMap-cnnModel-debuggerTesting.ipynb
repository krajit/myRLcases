{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03282ea6-95f8-4747-b01b-b46fe9b94415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.9.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:13:00,910\tINFO services.py:1470 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8267\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8267', python_version='3.9.12', ray_version='1.13.0', ray_commit='e4ce38d001dbbe09cd21c497fedd03d692b2be3e', address_info={'node_ip_address': '10.13.62.8', 'raylet_ip_address': '10.13.62.8', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-08-04_13-12-58_887918_51876/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-04_13-12-58_887918_51876/sockets/raylet', 'webui_url': '127.0.0.1:8267', 'session_dir': '/tmp/ray/session_2022-08-04_13-12-58_887918_51876', 'metrics_export_port': 58959, 'gcs_address': '10.13.62.8:45028', 'address': '10.13.62.8:45028', 'node_id': 'f5e84356f1009afb0e7bf17c157cbe30f668821f4560324f8c06269a'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import Num\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "\n",
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from typing import List, Optional\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map\n",
    "\n",
    "from newGenerate_random_map import newGenerate_random_map\n",
    "ray.init(local_mode=True, num_gpus=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa918f6-1bfb-490b-99c4-4846fef657e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedFrozenLake(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.desc = self.env.desc\n",
    "        self.size = len(self.desc)\n",
    "        self.old = np.where((env.desc==b'S').reshape(self.size**2,))[0]\n",
    "        self.goal = np.where((env.desc==b'G').reshape(self.size**2,))[0]\n",
    "        self.observation_space = gym.spaces.Box(-0.1,1.1,shape=(3,self.size,self.size,),dtype=\"float32\")\n",
    "        self.action_space = self.env.action_space\n",
    "        self.state_ = None\n",
    "        \n",
    "    def oneHot(self,s):\n",
    "        x = np.zeros(self.size*self.size)\n",
    "        x[s] = 1\n",
    "        state_ = np.array([ x.reshape(self.size,self.size),\n",
    "                         np.array(self.env.desc == b\"F\").astype(\"float32\"),\n",
    "                         np.array(self.env.desc == b\"G\").astype(\"float32\")\n",
    "                          ])\n",
    "        return state_.reshape(3,self.size,self.size,) + (0.1*np.random.rand(3,self.size,self.size,)-0.05)\n",
    "\n",
    "    def reset(self):\n",
    "        # return self.oneHot(1)\n",
    "        self.s = self.old\n",
    "        self.state_ = self.oneHot(self.env.reset())class WrappedFrozenLake(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.desc = self.env.desc\n",
    "        self.size = len(self.desc)\n",
    "        self.old = np.where((env.desc==b'S').reshape(self.size**2,))[0]\n",
    "        self.goal = np.where((env.desc==b'G').reshape(self.size**2,))[0]\n",
    "        self.observation_space = gym.spaces.Box(-0.1,1.1,shape=(3,self.size,self.size,),dtype=\"float32\")\n",
    "        self.action_space = self.env.action_space\n",
    "        self.state_ = None\n",
    "        \n",
    "    def oneHot(self,s):\n",
    "        x = np.zeros(self.size*self.size)\n",
    "        x[s] = 1\n",
    "        state_ = np.array([ x.reshape(self.size,self.size),\n",
    "                         np.array(self.env.desc == b\"F\").astype(\"float32\"),\n",
    "                         np.array(self.env.desc == b\"G\").astype(\"float32\")\n",
    "                          ])\n",
    "        return state_.reshape(3,self.size,self.size,) + (0.1*np.random.rand(3,self.size,self.size,)-0.05)\n",
    "\n",
    "    def reset(self):\n",
    "        # return self.oneHot(1)\n",
    "        self.s = self.old\n",
    "        self.state_ = self.oneHot(self.env.reset())\n",
    "        return self.state_\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, r, done, info = s\n",
    "        return self.state_\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, r, done, info = self.env.step(action)\n",
    "        \n",
    "        if obs == self.goal:\n",
    "            done = True\n",
    "            \n",
    "        if done:\n",
    "            reward = 2 if r > 0 else -1\n",
    "        elif obs == self.old:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 0\n",
    "        self.old = obs\n",
    "        self.state_ = self.oneHot(obs)\n",
    "        return self.state_, reward, done, info\n",
    "    \n",
    "    def render(self, mode=\"rgb_array\"):\n",
    "        sqSize = 20\n",
    "        canvasSize = sqSize*self.size+1\n",
    "        canvas = pygame.Surface((canvasSize, canvasSize))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        for i in range(self.size+2):\n",
    "            pygame.draw.line(canvas, 0, (0, sqSize*i), (canvasSize, sqSize*i), width=1)\n",
    "            pygame.draw.line(canvas, 0, ( sqSize*i,0), (sqSize*i,canvasSize, ), width=1)\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if (self.env.desc==b\"H\")[i,j]: # if there is a hole at ij\n",
    "                    blackColor = (0,0,0)\n",
    "                    pygame.draw.rect(canvas, blackColor, pygame.Rect(sqSize*(i)+1, sqSize*(j)+1, sqSize-1, sqSize-1))\n",
    "                if (self.env.desc==b\"G\")[i,j]: # if there is a gole at ij\n",
    "                    greenColor = (0,255,0)\n",
    "                    pygame.draw.rect(canvas, greenColor, pygame.Rect(sqSize*(i), sqSize*(j), sqSize, sqSize))\n",
    "                if self.state_[0,i,j] > 0.5:\n",
    "                    blueColor = (0,0,255)\n",
    "                    pygame.draw.circle(canvas, blueColor, (sqSize*i+sqSize/2,sqSize*j+sqSize/2) , sqSize/3)\n",
    "        \n",
    "        plArray = np.array(pygame.surfarray.pixels3d(canvas))\n",
    "        plt.imshow(plArray)        \n",
    "        plt.axis(\"off\")\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def env_creator(env_config): \n",
    "    size = env_config['size']\n",
    "    numHoles = env_config['numHoles']\n",
    "    p = 1-numHoles/(size**2)\n",
    "    desc = newGenerate_random_map(size=size, p=p)\n",
    "    return WrappedFrozenLake(gym.make('FrozenLake-v1', desc = desc, is_slippery=False))  # return an env instance\n",
    "\n",
    "register_env(\"myenv\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13337bb-777c-4c97-a40a-bc2a643d2827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = env_creator(env_config = {'size':6, 'numHoles': 10})\n",
    "env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    plt.cla()\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    obs, reward, done, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.1)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.gcf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ded3d8-452a-430e-9669-d510ea8d1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.framework import try_import_tf, try_import_torch\n",
    "\n",
    "torch, nn = try_import_torch()\n",
    "\n",
    "class MyTorchModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
    "                              model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        self.device = torch.device(\"cpu\")#\"cuda\"\n",
    "        #                            if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.mainLayer = nn.Sequential(\n",
    "                nn.Conv2d(3,12,kernel_size=3,stride= 1,padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(12,24,kernel_size=3,stride=1,padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(24,36,kernel_size=3,stride=1,padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.Flatten(start_dim=-3,end_dim=-1),\n",
    "                nn.Linear(1296,256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256,256),\n",
    "                nn.ReLU(),\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Action logits output.\n",
    "        self.layer_out = nn.Linear(256, num_outputs).to(self.device)\n",
    "\n",
    "        # \"Value\"-branch (single node output).\n",
    "        # Used by several RLlib algorithms (e.g. PPO) to calculate an observation's value.\n",
    "        self.value_branch = nn.Linear(256, 1).to(self.device)\n",
    "        self.cur_value = None\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        \"\"\"Custom-define your forard pass logic here.\"\"\"\n",
    "        # Pass inputs through our 2 layers.\n",
    "        layer_1_out = self.mainLayer(input_dict[\"obs\"])\n",
    "        logits = self.layer_out(layer_1_out)\n",
    "\n",
    "        # Calculate the \"value\" of the observation and store it for\n",
    "        # when `value_function` is called.\n",
    "        self.cur_value = self.value_branch(layer_1_out).squeeze(-1)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def value_function(self):\n",
    "        \"\"\"Implement the value branch forward pass logic here:\n",
    "        \n",
    "        We will just return the already calculated `self.cur_value`.\n",
    "        \"\"\"\n",
    "        assert self.cur_value is not None, \"Must call `forward()` first!\"\n",
    "        return self.cur_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89613814-2ead-496a-a4be-fa2f2942fdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0172,  0.0112, -0.0113, -0.0362], grad_fn=<AddBackward0>), [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 6\n",
    "test_model_torch = MyTorchModel(\n",
    "   obs_space=gym.spaces.Box(0,1,shape=(3,size,size), dtype=np.float32),\n",
    "   action_space=gym.spaces.Discrete(4),\n",
    "   num_outputs=4,\n",
    "   model_config={},\n",
    "   name=\"MyModel\",\n",
    ")\n",
    "#print(\"Torch-output={}\".format(test_model_torch({\"obs\": torch.from_numpy(np.array([[0.5, 0.5]], dtype=np.float32))})))\n",
    "\n",
    "obs = gym.spaces.Box(-0.1,1.1,shape=(3,size,size)).sample()\n",
    "test_model_torch({\"obs\": torch.from_numpy(obs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d875ff98-1145-45ce-b343-cd36683bc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"framework\": \"torch\",\n",
    "        \"env\":\"myenv\",  \n",
    "        \"env_config\":{'size':6, 'numHoles': 10},\n",
    "        \"num_workers\": 1,\n",
    "          \"model\": {\n",
    "             \"custom_model\": MyTorchModel,  # for torch users: \"custom_model\": MyTorchModel\n",
    "             \"custom_model_config\": {},\n",
    "          },\n",
    "        'num_envs_per_worker': 200,\n",
    "        \"create_env_on_driver\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d15567-ca54-4b3c-9a8c-385c6cbe743b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:13:16,430\tWARNING ppo.py:386 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=1 num_envs_per_worker=200 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 20.\n",
      "2022-08-04 13:13:16,435\tINFO ppo.py:414 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2022-08-04 13:13:16,437\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2022-08-04 13:13:16,645\tWARNING worker.py:525 -- `ray.get_gpu_ids()` will always return the empty list when called from the driver. This is because Ray does not manage GPU allocations to the driver process.\n",
      ":actor_name:RolloutWorker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":actor_name:RolloutWorker\n",
      "-1.126596980255517\n",
      "-1.2294520547945205\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "Canceled. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Create our RLlib Trainer.\n",
    "trainer = PPOTrainer(config=config)\n",
    "\n",
    "# Run it for n training iterations. A training iteration includes\n",
    "# parallel sample collection by the environment workers as well as\n",
    "# loss calculation on the collected batch and a model update.\n",
    "for _ in range(10):\n",
    "   analysis =  trainer.train()\n",
    "   print(analysis['sampler_results']['episode_reward_mean'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rllib-stable')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1b82eb6b91defcccb02b513f55e4a8555f19c3e8feea22de4e45418d1f17431"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
