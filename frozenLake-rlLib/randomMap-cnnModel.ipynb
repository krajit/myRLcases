{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8dfa69-741d-4968-b4c2-912eab5db7b7",
   "metadata": {},
   "source": [
    "# Frozen Lake env with Random starting and End Points, trained on RlLib\n",
    "\n",
    "![Frozen Lake](frozenLake_testing.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03282ea6-95f8-4747-b01b-b46fe9b94415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.9.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "\n",
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from typing import List, Optional\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map\n",
    "\n",
    "from newGenerate_random_map import newGenerate_random_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa918f6-1bfb-490b-99c4-4846fef657e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedFrozenLake(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.desc = self.env.desc\n",
    "        self.size = len(self.desc)\n",
    "        self.old = np.where((env.desc==b'S').reshape(self.size**2,))[0]\n",
    "        self.goal = np.where((env.desc==b'G').reshape(self.size**2,))[0]\n",
    "        self.observation_space = gym.spaces.Box(-0.1,1.1,shape=(3,self.size,self.size,),dtype=\"float32\")\n",
    "        self.action_space = self.env.action_space\n",
    "        self.state_ = None\n",
    "        \n",
    "    def oneHot(self,s):\n",
    "        x = np.zeros(self.size*self.size)\n",
    "        x[s] = 1\n",
    "        state_ = np.array([ x.reshape(self.size,self.size),\n",
    "                         np.array(self.env.desc == b\"F\").astype(\"float32\"),\n",
    "                         np.array(self.env.desc == b\"G\").astype(\"float32\")\n",
    "                          ])\n",
    "        return state_.reshape(3,self.size,self.size,) + (0.1*np.random.rand(3,self.size,self.size,)-0.05)\n",
    "\n",
    "    def reset(self):\n",
    "        # return self.oneHot(1)\n",
    "        self.s = self.old\n",
    "        self.state_ = self.oneHot(self.env.reset())\n",
    "        return self.state_\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, r, done, info = self.env.step(action)\n",
    "        \n",
    "        if obs == self.goal:\n",
    "            done = True\n",
    "            \n",
    "        if done:\n",
    "            reward = 2 if r > 0 else -1\n",
    "        elif obs == self.old:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 0\n",
    "        self.old = obs\n",
    "        self.state_ = self.oneHot(obs)\n",
    "        return self.state_, reward, done, info\n",
    "    \n",
    "    def render(self, mode=\"rgb_array\"):\n",
    "        sqSize = 20\n",
    "        canvasSize = sqSize*self.size+1\n",
    "        canvas = pygame.Surface((canvasSize, canvasSize))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        for i in range(self.size+2):\n",
    "            pygame.draw.line(canvas, 0, (0, sqSize*i), (canvasSize, sqSize*i), width=1)\n",
    "            pygame.draw.line(canvas, 0, ( sqSize*i,0), (sqSize*i,canvasSize, ), width=1)\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if (self.env.desc==b\"H\")[i,j]: # if there is a hole at ij\n",
    "                    blackColor = (0,0,0)\n",
    "                    pygame.draw.rect(canvas, blackColor, pygame.Rect(sqSize*(i)+1, sqSize*(j)+1, sqSize-1, sqSize-1))\n",
    "                if (self.env.desc==b\"G\")[i,j]: # if there is a gole at ij\n",
    "                    greenColor = (0,255,0)\n",
    "                    pygame.draw.rect(canvas, greenColor, pygame.Rect(sqSize*(i), sqSize*(j), sqSize, sqSize))\n",
    "                if self.state_[0,i,j] > 0.5:\n",
    "                    blueColor = (0,0,255)\n",
    "                    pygame.draw.circle(canvas, blueColor, (sqSize*i+sqSize/2,sqSize*j+sqSize/2) , sqSize/3)\n",
    "        \n",
    "        plArray = np.array(pygame.surfarray.pixels3d(canvas))\n",
    "        plt.imshow(plArray)        \n",
    "        plt.axis(\"off\")\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def env_creator(env_config): \n",
    "    size = env_config['size']\n",
    "    numHoles = env_config['numHoles']\n",
    "    p = 1-numHoles/(size**2)\n",
    "    desc = newGenerate_random_map(size=size, p=p)\n",
    "    return WrappedFrozenLake(gym.make('FrozenLake-v1', desc = desc, is_slippery=False))  # return an env instance\n",
    "\n",
    "register_env(\"myenv\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13337bb-777c-4c97-a40a-bc2a643d2827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = env_creator(env_config = {'size':6, 'numHoles': 10})\n",
    "env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    plt.cla()\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    obs, reward, done, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.1)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.gcf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ded3d8-452a-430e-9669-d510ea8d1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.framework import try_import_tf, try_import_torch\n",
    "\n",
    "torch, nn = try_import_torch()\n",
    "\n",
    "class MyTorchModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
    "                              model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        self.device = torch.device(\"cpu\")#\"cuda\"\n",
    "        #                            if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.mainLayer = nn.Sequential(\n",
    "                nn.Conv2d(3,12,kernel_size=3,stride= 1,padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(12,24,kernel_size=3,stride=1,padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(24,36,kernel_size=3,stride=1,padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.Flatten(start_dim=-3,end_dim=-1),\n",
    "                nn.Linear(1296,256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256,256),\n",
    "                nn.ReLU(),\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Action logits output.\n",
    "        self.layer_out = nn.Linear(256, num_outputs).to(self.device)\n",
    "\n",
    "        # \"Value\"-branch (single node output).\n",
    "        # Used by several RLlib algorithms (e.g. PPO) to calculate an observation's value.\n",
    "        self.value_branch = nn.Linear(256, 1).to(self.device)\n",
    "        self.cur_value = None\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        \"\"\"Custom-define your forard pass logic here.\"\"\"\n",
    "        # Pass inputs through our 2 layers.\n",
    "        layer_1_out = self.mainLayer(input_dict[\"obs\"])\n",
    "        logits = self.layer_out(layer_1_out)\n",
    "\n",
    "        # Calculate the \"value\" of the observation and store it for\n",
    "        # when `value_function` is called.\n",
    "        self.cur_value = self.value_branch(layer_1_out).squeeze(-1)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def value_function(self):\n",
    "        \"\"\"Implement the value branch forward pass logic here:\n",
    "        \n",
    "        We will just return the already calculated `self.cur_value`.\n",
    "        \"\"\"\n",
    "        assert self.cur_value is not None, \"Must call `forward()` first!\"\n",
    "        return self.cur_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89613814-2ead-496a-a4be-fa2f2942fdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0542,  0.0447, -0.0216, -0.0007], grad_fn=<AddBackward0>), [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 6\n",
    "test_model_torch = MyTorchModel(\n",
    "   obs_space=gym.spaces.Box(0,1,shape=(3,size,size), dtype=np.float32),\n",
    "   action_space=gym.spaces.Discrete(4),\n",
    "   num_outputs=4,\n",
    "   model_config={},\n",
    "   name=\"MyModel\",\n",
    ")\n",
    "#print(\"Torch-output={}\".format(test_model_torch({\"obs\": torch.from_numpy(np.array([[0.5, 0.5]], dtype=np.float32))})))\n",
    "\n",
    "obs = gym.spaces.Box(-0.1,1.1,shape=(3,size,size)).sample()\n",
    "test_model_torch({\"obs\": torch.from_numpy(obs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d875ff98-1145-45ce-b343-cd36683bc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"framework\": \"torch\",\n",
    "        \"env\":\"myenv\",  \n",
    "        \"env_config\":{'size':6, 'numHoles': 10},\n",
    "        \"num_workers\": 10,\n",
    "          \"model\": {\n",
    "             \"custom_model\": MyTorchModel,  # for torch users: \"custom_model\": MyTorchModel\n",
    "             \"custom_model_config\": {},\n",
    "          },\n",
    "        'num_envs_per_worker': 200,\n",
    "        \"create_env_on_driver\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d15567-ca54-4b3c-9a8c-385c6cbe743b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-25 10:52:57 (running for 00:11:13.52)<br>Memory usage on this node: 7.0/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/77.06 GiB heap, 0.0/37.02 GiB objects<br>Result logdir: /home/ajit/Desktop/myRLcases/frozenLake-rlLib/checkPoints/PPO<br>Number of trials: 1/1 (1 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 10:52:58,519\tINFO tune.py:747 -- Total run time: 674.41 seconds (673.46 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "tune_config = config.copy()\n",
    "tune_config[\"lr\"] = tune.grid_search([0.0001])  # <- 0.5? again: ouch!\n",
    "\n",
    "stop = {\n",
    "    \"training_iteration\": 50,\n",
    "    \"episode_reward_mean\": 1.90,\n",
    "}\n",
    "\n",
    "analysis =  tune.run(\n",
    "    \"PPO\",\n",
    "    config=tune_config,\n",
    "    stop=stop,\n",
    "    checkpoint_at_end=True,  \n",
    "    checkpoint_freq=5,  \n",
    "    local_dir=\"checkPoints/\",\n",
    "    verbose=1,\n",
    "    #resume=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ba06c8a-bf47-41c2-837d-d43356e2255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x7fb628202910>\n",
      "Found best checkpoint for trial #2: /home/ajit/Desktop/myRLcases/frozenLake-rlLib/checkPoints/PPO/PPO_myenv_46839_00000_0_lr=0.0001_2022-07-25_10-41-44/checkpoint_000050/checkpoint-50\n"
     ]
    }
   ],
   "source": [
    "# The previous tune.run (the one we did before the exercise) returned an Analysis object, from which we can access any checkpoint\n",
    "# (given we set checkpoint_freq or checkpoint_at_end to reasonable values) like so:\n",
    "print(analysis)\n",
    "# Get all trials (we only have one).\n",
    "trials = analysis.trials\n",
    "# Assuming, the first trial was the best, we'd like to extract this trial's best checkpoint \"\":\n",
    "best_checkpoint = analysis.get_best_checkpoint(trial=trials[0], metric=\"episode_reward_mean\", mode=\"max\")\n",
    "print(f\"Found best checkpoint for trial #2: {best_checkpoint}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ff5d9-896a-4229-a3e3-b33e093b0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rllib_config = tune_config.copy()\n",
    "rllib_config[\"lr\"] = 0.0001\n",
    "#rllib_config[\"train_batch_size\"] = 4159\n",
    "rllib_config[\"explore\"] = False\n",
    "\n",
    "# Restore a RLlib Trainer from the checkpoint.\n",
    "new_trainer = PPOTrainer(config=rllib_config)\n",
    "new_trainer.restore(best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b63a14e-27bb-4b3a-8e7c-625e867b4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b93a3da2-3f53-4b3e-95d0-7ac37caf9264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-78.0\n"
     ]
    }
   ],
   "source": [
    "won = 0\n",
    "lost = 0\n",
    "rewardList = []\n",
    "\n",
    "for i in range(10):\n",
    "    env = env_creator({'size':6, 'numHoles': 10}) #gym.make(\"myenv-v1\")#\"FrozenLake-v1\")\n",
    "    #, #FrozenLakeWrapped({})\n",
    "    # Get the initial observation (should be: [0.0] for the starting position).\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    # Play one episode.\n",
    "    while not done:\n",
    "        # plt.cla()\n",
    "#        display.clear_output(wait=True)\n",
    "        # print(\"num won: \", won, \" played: \", i, \"total reward: \", total_reward)\n",
    "        # env.render()\n",
    "\n",
    "        action = new_trainer.compute_single_action(obs,explore=False)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        #print(obs, reward, done)\n",
    "        total_reward += reward\n",
    "        # time.sleep(0.1)\n",
    "        \n",
    "        # display.display(plt.gcf())\n",
    "        # plt.gcf()\n",
    "        if done: \n",
    "            rewardList.append(total_reward)\n",
    "    if reward > 0 :\n",
    "        won +=1 \n",
    "      \n",
    "    \n",
    "#print(rewardList, np.mean(rewardList))\n",
    "print( np.mean(rewardList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "036ddce9-a83c-4f85-a128-d98911eff4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b27fd-5647-4b1a-b350-e05b328baf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "numPlay = 20\n",
    "won = 0\n",
    "for i in range(numPlay):\n",
    "    env = env_creator({'size':6, 'numHoles': 10})# gym.make(\"FrozenLake-v1\")\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    # Play one episode.\n",
    "    while not done:\n",
    "        print(\"Played: \", i, \", won: \",won)\n",
    "\n",
    "        plt.cla()\n",
    "#        display.clear_output(wait=True)\n",
    "        obs, reward, done, info = env.step(new_trainer.compute_single_action(obs,explore=False))\n",
    "        if done and reward > 0:\n",
    "            won += 1\n",
    "        env.render()\n",
    "\n",
    "        time.sleep(0.1)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "#        plt.gcf()\n",
    "print(\"Played: \", numPlay, \", won: \",won)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e73753c9-fd91-4f3b-85d9-6854e0f4b81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b0313-e19e-4775-b354-b8a40330b529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
