{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8dfa69-741d-4968-b4c2-912eab5db7b7",
   "metadata": {},
   "source": [
    "# Frozen Lake env with Random starting and End Points, trained on RlLib\n",
    "\n",
    "![Frozen Lake](frozenLake_testing.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03282ea6-95f8-4747-b01b-b46fe9b94415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.9.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "\n",
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from typing import List, Optional\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map\n",
    "\n",
    "from newGenerate_random_map import newGenerate_random_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa918f6-1bfb-490b-99c4-4846fef657e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedFrozenLake(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.desc = self.env.desc\n",
    "        self.size = len(self.desc)\n",
    "        self.old = np.where((env.desc==b'S').reshape(self.size**2,))[0]\n",
    "        self.goal = np.where((env.desc==b'G').reshape(self.size**2,))[0]\n",
    "        self.observation_space = gym.spaces.Box(-0.1,1.1,shape=(3,self.size,self.size,),dtype=\"float32\")\n",
    "        self.action_space = self.env.action_space\n",
    "        self.state_ = None\n",
    "        \n",
    "    def oneHot(self,s):\n",
    "        x = np.zeros(self.size*self.size)\n",
    "        x[s] = 1\n",
    "        state_ = np.array([ x.reshape(self.size,self.size),\n",
    "                         np.array(self.env.desc == b\"F\").astype(\"float32\"),\n",
    "                         np.array(self.env.desc == b\"G\").astype(\"float32\")\n",
    "                          ])\n",
    "        return state_.reshape(3,self.size,self.size,) + (0.1*np.random.rand(3,self.size,self.size,)-0.05)\n",
    "\n",
    "    def reset(self):\n",
    "        # return self.oneHot(1)\n",
    "        self.s = self.old\n",
    "        self.state_ = self.oneHot(self.env.reset())\n",
    "        return self.state_\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, r, done, info = self.env.step(action)\n",
    "        \n",
    "        if obs == self.goal:\n",
    "            done = True\n",
    "            \n",
    "        if done:\n",
    "            reward = 2 if r > 0 else -1\n",
    "        elif obs == self.old:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 0\n",
    "        self.old = obs\n",
    "        self.state_ = self.oneHot(obs)\n",
    "        return self.state_, reward, done, info\n",
    "    \n",
    "    def render(self, mode=\"rgb_array\"):\n",
    "        sqSize = 20\n",
    "        canvasSize = sqSize*self.size+1\n",
    "        canvas = pygame.Surface((canvasSize, canvasSize))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        for i in range(self.size+2):\n",
    "            pygame.draw.line(canvas, 0, (0, sqSize*i), (canvasSize, sqSize*i), width=1)\n",
    "            pygame.draw.line(canvas, 0, ( sqSize*i,0), (sqSize*i,canvasSize, ), width=1)\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if (self.env.desc==b\"H\")[i,j]: # if there is a hole at ij\n",
    "                    blackColor = (0,0,0)\n",
    "                    pygame.draw.rect(canvas, blackColor, pygame.Rect(sqSize*(i)+1, sqSize*(j)+1, sqSize-1, sqSize-1))\n",
    "                if (self.env.desc==b\"G\")[i,j]: # if there is a gole at ij\n",
    "                    greenColor = (0,255,0)\n",
    "                    pygame.draw.rect(canvas, greenColor, pygame.Rect(sqSize*(i), sqSize*(j), sqSize, sqSize))\n",
    "                if self.state_[0,i,j] > 0.5:\n",
    "                    blueColor = (0,0,255)\n",
    "                    pygame.draw.circle(canvas, blueColor, (sqSize*i+sqSize/2,sqSize*j+sqSize/2) , sqSize/3)\n",
    "        \n",
    "        plArray = np.array(pygame.surfarray.pixels3d(canvas))\n",
    "        plt.imshow(plArray)        \n",
    "        plt.axis(\"off\")\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def env_creator(env_config): \n",
    "    size = env_config['size']\n",
    "    numHoles = env_config['numHoles']\n",
    "    p = 1-numHoles/(size**2)\n",
    "    desc = newGenerate_random_map(size=size, p=p)\n",
    "    return WrappedFrozenLake(gym.make('FrozenLake-v1', desc = desc, is_slippery=False))  # return an env instance\n",
    "\n",
    "register_env(\"myenv\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13337bb-777c-4c97-a40a-bc2a643d2827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = env_creator(env_config = {'size':6, 'numHoles': 10})\n",
    "env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    plt.cla()\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    obs, reward, done, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.1)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.gcf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ded3d8-452a-430e-9669-d510ea8d1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.framework import try_import_tf, try_import_torch\n",
    "\n",
    "torch, nn = try_import_torch()\n",
    "\n",
    "class MyTorchModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
    "                              model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        self.device = torch.device(\"cpu\")#\"cuda\"\n",
    "        #                            if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.mainLayer = nn.Sequential(\n",
    "                nn.Conv2d(3,12,kernel_size=3,stride= 1,padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(12,24,kernel_size=3,stride=1,padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(24,36,kernel_size=3,stride=1,padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.Flatten(start_dim=-3,end_dim=-1),\n",
    "                nn.Linear(1296,256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256,256),\n",
    "                nn.ReLU(),\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Action logits output.\n",
    "        self.layer_out = nn.Linear(256, num_outputs).to(self.device)\n",
    "\n",
    "        # \"Value\"-branch (single node output).\n",
    "        # Used by several RLlib algorithms (e.g. PPO) to calculate an observation's value.\n",
    "        self.value_branch = nn.Linear(256, 1).to(self.device)\n",
    "        self.cur_value = None\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        \"\"\"Custom-define your forard pass logic here.\"\"\"\n",
    "        # Pass inputs through our 2 layers.\n",
    "        layer_1_out = self.mainLayer(input_dict[\"obs\"])\n",
    "        logits = self.layer_out(layer_1_out)\n",
    "\n",
    "        # Calculate the \"value\" of the observation and store it for\n",
    "        # when `value_function` is called.\n",
    "        self.cur_value = self.value_branch(layer_1_out).squeeze(-1)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def value_function(self):\n",
    "        \"\"\"Implement the value branch forward pass logic here:\n",
    "        \n",
    "        We will just return the already calculated `self.cur_value`.\n",
    "        \"\"\"\n",
    "        assert self.cur_value is not None, \"Must call `forward()` first!\"\n",
    "        return self.cur_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89613814-2ead-496a-a4be-fa2f2942fdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0372,  0.0805, -0.0337, -0.0015], grad_fn=<AddBackward0>), [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 6\n",
    "test_model_torch = MyTorchModel(\n",
    "   obs_space=gym.spaces.Box(0,1,shape=(3,size,size), dtype=np.float32),\n",
    "   action_space=gym.spaces.Discrete(4),\n",
    "   num_outputs=4,\n",
    "   model_config={},\n",
    "   name=\"MyModel\",\n",
    ")\n",
    "#print(\"Torch-output={}\".format(test_model_torch({\"obs\": torch.from_numpy(np.array([[0.5, 0.5]], dtype=np.float32))})))\n",
    "\n",
    "obs = gym.spaces.Box(-0.1,1.1,shape=(3,size,size)).sample()\n",
    "test_model_torch({\"obs\": torch.from_numpy(obs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d875ff98-1145-45ce-b343-cd36683bc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"framework\": \"torch\",\n",
    "        \"env\":\"myenv\",  \n",
    "        \"env_config\":{'size':6, 'numHoles': 10},\n",
    "        \"num_workers\": 10,\n",
    "          \"model\": {\n",
    "             \"custom_model\": MyTorchModel,  # for torch users: \"custom_model\": MyTorchModel\n",
    "             \"custom_model_config\": {},\n",
    "          },\n",
    "        'num_envs_per_worker': 200,\n",
    "        \"create_env_on_driver\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d15567-ca54-4b3c-9a8c-385c6cbe743b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-08-04 12:10:54 (running for 00:00:33.02)<br>Memory usage on this node: 10.3/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 11.0/16 CPUs, 0/1 GPUs, 0.0/75.3 GiB heap, 0.0/36.26 GiB objects (0.0/1.0 accelerator_type:RTX)<br>Result logdir: /home/ajit/Desktop/myRLcases/frozenLake-rlLib/checkPoints/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m tune_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mgrid_search([\u001b[38;5;241m0.0001\u001b[39m])  \u001b[38;5;66;03m# <- 0.5? again: ouch!\u001b[39;00m\n\u001b[1;32m      5\u001b[0m stop \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_reward_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1.90\u001b[39m,\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m---> 10\u001b[0m analysis \u001b[38;5;241m=\u001b[39m  \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPPO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckPoints/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#resume=True\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/tune/tune.py:732\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, loggers, _remote)\u001b[0m\n\u001b[1;32m    729\u001b[0m     _report_progress(runner, progress_reporter, done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    731\u001b[0m wait_for_sync()\n\u001b[0;32m--> 732\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m incomplete_trials \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mget_trials():\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/tune/trial_runner.py:1373\u001b[0m, in \u001b[0;36mTrialRunner.cleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;124;03m\"\"\"Cleanup trials and callbacks.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1373\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_experiment_callbacks()\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/tune/trial_runner.py:1369\u001b[0m, in \u001b[0;36mTrialRunner.cleanup_trials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanup_trials\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1369\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/tune/ray_trial_executor.py:781\u001b[0m, in \u001b[0;36mRayTrialExecutor.cleanup\u001b[0;34m(self, trials)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_force_trial_cleanup()\n\u001b[0;32m--> 781\u001b[0m ready, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_futures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ready:\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/worker.py:2015\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2013\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   2014\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 2015\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2021\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1403\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:169\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "tune_config = config.copy()\n",
    "tune_config[\"lr\"] = tune.grid_search([0.0001])  # <- 0.5? again: ouch!\n",
    "\n",
    "stop = {\n",
    "    \"training_iteration\": 50,\n",
    "    \"episode_reward_mean\": 1.90,\n",
    "}\n",
    "\n",
    "analysis =  tune.run(\n",
    "    \"PPO\",\n",
    "    config=tune_config,\n",
    "    stop=stop,\n",
    "    checkpoint_at_end=True,  \n",
    "    checkpoint_freq=5,  \n",
    "    local_dir=\"checkPoints/\",\n",
    "    verbose=1,\n",
    "    #resume=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba06c8a-bf47-41c2-837d-d43356e2255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous tune.run (the one we did before the exercise) returned an Analysis object, from which we can access any checkpoint\n",
    "# (given we set checkpoint_freq or checkpoint_at_end to reasonable values) like so:\n",
    "print(analysis)\n",
    "# Get all trials (we only have one).\n",
    "trials = analysis.trials\n",
    "# Assuming, the first trial was the best, we'd like to extract this trial's best checkpoint \"\":\n",
    "best_checkpoint = analysis.get_best_checkpoint(trial=trials[0], metric=\"episode_reward_mean\", mode=\"max\")\n",
    "print(f\"Found best checkpoint for trial #2: {best_checkpoint}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ff5d9-896a-4229-a3e3-b33e093b0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rllib_config = tune_config.copy()\n",
    "rllib_config[\"lr\"] = 0.0001\n",
    "#rllib_config[\"train_batch_size\"] = 4159\n",
    "rllib_config[\"explore\"] = False\n",
    "\n",
    "# Restore a RLlib Trainer from the checkpoint.\n",
    "new_trainer = PPOTrainer(config=rllib_config)\n",
    "new_trainer.restore(best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b63a14e-27bb-4b3a-8e7c-625e867b4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b93a3da2-3f53-4b3e-95d0-7ac37caf9264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-78.0\n"
     ]
    }
   ],
   "source": [
    "won = 0\n",
    "lost = 0\n",
    "rewardList = []\n",
    "\n",
    "for i in range(10):\n",
    "    env = env_creator({'size':6, 'numHoles': 10}) #gym.make(\"myenv-v1\")#\"FrozenLake-v1\")\n",
    "    #, #FrozenLakeWrapped({})\n",
    "    # Get the initial observation (should be: [0.0] for the starting position).\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    # Play one episode.\n",
    "    while not done:\n",
    "        # plt.cla()\n",
    "#        display.clear_output(wait=True)\n",
    "        # print(\"num won: \", won, \" played: \", i, \"total reward: \", total_reward)\n",
    "        # env.render()\n",
    "\n",
    "        action = new_trainer.compute_single_action(obs,explore=False)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        #print(obs, reward, done)\n",
    "        total_reward += reward\n",
    "        # time.sleep(0.1)\n",
    "        \n",
    "        # display.display(plt.gcf())\n",
    "        # plt.gcf()\n",
    "        if done: \n",
    "            rewardList.append(total_reward)\n",
    "    if reward > 0 :\n",
    "        won +=1 \n",
    "      \n",
    "    \n",
    "#print(rewardList, np.mean(rewardList))\n",
    "print( np.mean(rewardList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "036ddce9-a83c-4f85-a128-d98911eff4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b27fd-5647-4b1a-b350-e05b328baf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "numPlay = 20\n",
    "won = 0\n",
    "for i in range(numPlay):\n",
    "    env = env_creator({'size':6, 'numHoles': 10})# gym.make(\"FrozenLake-v1\")\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    # Play one episode.\n",
    "    while not done:\n",
    "        print(\"Played: \", i, \", won: \",won)\n",
    "\n",
    "        plt.cla()\n",
    "#        display.clear_output(wait=True)\n",
    "        obs, reward, done, info = env.step(new_trainer.compute_single_action(obs,explore=False))\n",
    "        if done and reward > 0:\n",
    "            won += 1\n",
    "        env.render()\n",
    "\n",
    "        time.sleep(0.1)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "#        plt.gcf()\n",
    "print(\"Played: \", numPlay, \", won: \",won)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73753c9-fd91-4f3b-85d9-6854e0f4b81e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCartPole-v1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      3\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b0313-e19e-4775-b354-b8a40330b529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
