{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f349cd-173b-4891-81cd-649ab62cd6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-08-16 14:06:52 (running for 00:00:30.37)<br>Memory usage on this node: 5.6/13.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/5.52 GiB heap, 0.0/2.76 GiB objects<br>Result logdir: /home/ajit/Desktop/myRLcases/misc/checkPoints/MBMPO<br>Number of trials: 1/1 (1 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajit/anaconda3/envs/rllib/lib/python3.9/site-packages/ray/util/placement_group.py:78: DeprecationWarning: placement_group parameter is deprecated. Use scheduling_strategy=PlacementGroupSchedulingStrategy(...) instead, see the usage at https://docs.ray.io/en/master/ray-core/package-ref.html#ray-remote.\n",
      "  return bundle_reservation_check.options(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ray.rllib.examples.env.mbmpo_env import CartPoleWrapper\n",
    "from ray import tune\n",
    "\n",
    "config = {\n",
    "        \"env\":CartPoleWrapper,  \n",
    "       \"framework\": \"torch\",\n",
    "        #horizon: 200,\n",
    "        \"num_envs_per_worker\": 20,\n",
    "        \"inner_adaptation_steps\": 1,\n",
    "        \"maml_optimizer_steps\": 8,\n",
    "        \"gamma\": 0.99,\n",
    "        \"lambda\": 1.0,\n",
    "        \"lr\": 0.001,\n",
    "        \"clip_param\": 0.5,\n",
    "        \"kl_target\": 0.003,\n",
    "        \"kl_coeff\": 0.0000000001,\n",
    "        \"num_workers\": 8,\n",
    "        \"num_gpus\": 0,\n",
    "        \"inner_lr\": 0.001,\n",
    "        \"clip_actions\": False,\n",
    "        \"num_maml_steps\": 15,\n",
    "        \"model\": {\n",
    "            \"fcnet_hiddens\": [32, 32],\n",
    "            \"free_log_std\": True,\n",
    "        }        \n",
    "}\n",
    "\n",
    "stop = {\n",
    "   \"episode_reward_mean\": 190,\n",
    "   \"training_iteration\": 20\n",
    "}\n",
    "\n",
    "analysis =  tune.run(\n",
    "    \"MBMPO\",\n",
    "    config=config,\n",
    "    stop=stop,\n",
    "    checkpoint_at_end=True,  \n",
    "    checkpoint_freq=5,  \n",
    "    local_dir=\"checkPoints/\",\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44be24-3145-4df8-a0f6-80caf30c55cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "#        \"framework\": \"torch\",\n",
    "        \"env\":\"FrozenLake-v1\",  \n",
    "#        \"env_config\":{'size':6, 'numHoles': 10},\n",
    "        \"num_workers\": 4,\n",
    "          # \"model\": {\n",
    "          #    \"custom_model\": MyTorchModel,  # for torch users: \"custom_model\": MyTorchModel\n",
    "          #    \"custom_model_config\": {},\n",
    "          # },\n",
    "#        'num_envs_per_worker': 20,\n",
    "        \"create_env_on_driver\": True,\n",
    "    \n",
    "}\n",
    "\n",
    "# trainer = DQNTrainer(\n",
    "#     env=, \n",
    "#     config={\n",
    "#         \"train_batch_size\": 400,\n",
    "#         \"n_step\": 2, # multistep\n",
    "#         \"num_atoms\": 4,  # for distributional DQN\n",
    "#         \"v_min\": 0.0, \n",
    "#         \"v_max\": 1.0\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296faf7-a4ef-4dfd-bf92-ec9636cc09c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-25 14:19:45 (running for 00:00:20.94)<br>Memory usage on this node: 6.4/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/76.83 GiB heap, 0.0/36.92 GiB objects (0.0/1.0 accelerator_type:RTX)<br>Result logdir: /home/ajit/Desktop/myRLcases/misc/checkPoints/DQN<br>Number of trials: 1/1 (1 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 14:19:46,262\tINFO tune.py:747 -- Total run time: 21.56 seconds (20.91 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "tune_config = config.copy()\n",
    "tune_config[\"lr\"] = tune.grid_search([0.0001])  # <- 0.5? again: ouch!\n",
    "\n",
    "stop = {\n",
    "    \"training_iteration\": 5,\n",
    "    \"episode_reward_mean\": 0.9,\n",
    "}\n",
    "\n",
    "analysis =  tune.run(\n",
    "    \"DQN\",\n",
    "    config=tune_config,\n",
    "    stop=stop,\n",
    "    checkpoint_at_end=True,  \n",
    "    checkpoint_freq=1,  \n",
    "    local_dir=\"checkPoints/\",\n",
    "    verbose=1,\n",
    "    #resume=True,\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f23f4-6fe5-456b-86a2-88ca1361894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis object at 0x7faba05613a0>\n",
      "Found best checkpoint for trial #2: /home/ajit/Desktop/myRLcases/misc/checkPoints/DQN/DQN_FrozenLake-v1_af392_00000_0_lr=0.0001_2022-07-25_14-19-25/checkpoint_000005/checkpoint-5\n"
     ]
    }
   ],
   "source": [
    "# The previous tune.run (the one we did before the exercise) returned an Analysis object, from which we can access any checkpoint\n",
    "# (given we set checkpoint_freq or checkpoint_at_end to reasonable values) like so:\n",
    "print(analysis)\n",
    "# Get all trials (we only have one).\n",
    "trials = analysis.trials\n",
    "# Assuming, the first trial was the best, we'd like to extract this trial's best checkpoint \"\":\n",
    "best_checkpoint = analysis.get_best_checkpoint(trial=trials[0], metric=\"episode_reward_mean\", mode=\"max\")\n",
    "print(f\"Found best checkpoint for trial #2: {best_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82557e2-fd5c-408e-a865-d74616f5b781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 14:20:08,450\tINFO trainer.py:2332 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2022-07-25 14:20:08,455\tINFO simple_q.py:187 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "2022-07-25 14:20:08,456\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    }
   ],
   "source": [
    "rllib_config = tune_config.copy()\n",
    "rllib_config[\"lr\"] = 0.0001\n",
    "#rllib_config[\"train_batch_size\"] = 4159\n",
    "rllib_config[\"explore\"] = False\n",
    "\n",
    "# Restore a RLlib Trainer from the checkpoint.\n",
    "new_trainer = DQNTrainer(config=rllib_config)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62fefb-83ab-4cdf-b982-12c537a9da74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ajit/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/rllib/utils/exploration/epsilon_greedy.py:241: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 14:20:09,975\tINFO trainable.py:588 -- Restored on 10.13.62.8 from checkpoint: /home/ajit/Desktop/myRLcases/misc/checkPoints/DQN/DQN_FrozenLake-v1_af392_00000_0_lr=0.0001_2022-07-25_14-19-25/checkpoint_000005/checkpoint-5\n",
      "2022-07-25 14:20:09,977\tINFO trainable.py:597 -- Current state after restoring: {'_iteration': 5, '_timesteps_total': None, '_time_total': 15.44607949256897, '_episodes_total': 602}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9094)\u001b[0m WARNING:tensorflow:From /home/ajit/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/rllib/utils/exploration/epsilon_greedy.py:241: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9094)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9094)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9095)\u001b[0m WARNING:tensorflow:From /home/ajit/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/rllib/utils/exploration/epsilon_greedy.py:241: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9095)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9095)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9096)\u001b[0m WARNING:tensorflow:From /home/ajit/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/rllib/utils/exploration/epsilon_greedy.py:241: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9096)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9096)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9093)\u001b[0m WARNING:tensorflow:From /home/ajit/anaconda3/envs/rllib-stable/lib/python3.9/site-packages/ray/rllib/utils/exploration/epsilon_greedy.py:241: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9093)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=9093)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    }
   ],
   "source": [
    "new_trainer.restore(best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444bbcb-b871-4109-bbac-008d0f486a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'episode_reward_max': 0.0,\n",
       "  'episode_reward_min': 0.0,\n",
       "  'episode_reward_mean': 0.0,\n",
       "  'episode_len_mean': 19.5,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 2,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [0.0, 0.0], 'episode_lengths': [2, 37]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.4772325841391959,\n",
       "   'mean_inference_ms': 4.362298221122928,\n",
       "   'mean_action_processing_ms': 0.14910465333519912,\n",
       "   'mean_env_wait_ms': 0.12515812385372999,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'timesteps_this_iter': 40}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be365e-3886-4230-b912-c668e37744f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rllib')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4f776a727d460e0bd4838751ebe198557dfb02a6bdf255e7525c0410567655d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
