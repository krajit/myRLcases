{"episode_reward_max": 121.0, "episode_reward_min": 8.0, "episode_reward_mean": 28.076923076923077, "episode_len_mean": 28.076923076923077, "episode_media": {}, "episodes_this_iter": 143, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.0, 33.0, 12.0, 16.0, 10.0, 21.0, 22.0, 23.0, 29.0, 27.0, 34.0, 32.0, 21.0, 19.0, 20.0, 16.0, 17.0, 18.0, 33.0, 18.0, 22.0, 10.0, 13.0, 15.0, 28.0, 12.0, 15.0, 34.0, 24.0, 8.0, 18.0, 24.0, 35.0, 18.0, 22.0, 14.0, 14.0, 20.0, 26.0, 21.0, 14.0, 11.0, 60.0, 41.0, 15.0, 17.0, 12.0, 69.0, 20.0, 24.0, 16.0, 23.0, 17.0, 19.0, 42.0, 39.0, 31.0, 29.0, 17.0, 15.0, 50.0, 19.0, 48.0, 39.0, 44.0, 32.0, 21.0, 68.0, 57.0, 17.0, 81.0, 26.0, 37.0, 33.0, 50.0, 59.0, 24.0, 19.0, 23.0, 17.0, 66.0, 36.0, 30.0, 36.0, 29.0, 18.0, 17.0, 12.0, 25.0, 47.0, 14.0, 50.0, 29.0, 17.0, 48.0, 18.0, 16.0, 17.0, 19.0, 121.0, 32.0, 27.0, 45.0, 18.0, 19.0, 41.0, 26.0, 22.0, 16.0, 31.0, 24.0, 17.0, 13.0, 11.0, 21.0, 22.0, 62.0, 33.0, 59.0, 49.0, 42.0, 35.0, 13.0, 20.0, 14.0, 20.0, 43.0, 16.0, 13.0, 17.0, 34.0, 27.0, 48.0, 35.0, 55.0, 15.0, 13.0, 32.0, 14.0, 28.0, 17.0, 66.0, 17.0], "episode_lengths": [19, 33, 12, 16, 10, 21, 22, 23, 29, 27, 34, 32, 21, 19, 20, 16, 17, 18, 33, 18, 22, 10, 13, 15, 28, 12, 15, 34, 24, 8, 18, 24, 35, 18, 22, 14, 14, 20, 26, 21, 14, 11, 60, 41, 15, 17, 12, 69, 20, 24, 16, 23, 17, 19, 42, 39, 31, 29, 17, 15, 50, 19, 48, 39, 44, 32, 21, 68, 57, 17, 81, 26, 37, 33, 50, 59, 24, 19, 23, 17, 66, 36, 30, 36, 29, 18, 17, 12, 25, 47, 14, 50, 29, 17, 48, 18, 16, 17, 19, 121, 32, 27, 45, 18, 19, 41, 26, 22, 16, 31, 24, 17, 13, 11, 21, 22, 62, 33, 59, 49, 42, 35, 13, 20, 14, 20, 43, 16, 13, 17, 34, 27, 48, 35, 55, 15, 13, 32, 14, 28, 17, 66, 17]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.172808908647105, "mean_inference_ms": 1.3879053054317347, "mean_action_processing_ms": 0.41366046474825946, "mean_env_wait_ms": 0.4236948105596727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 4, "timesteps_total": 8021, "timesteps_this_iter": 32000, "agent_timesteps_total": 0, "timers": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": [6.25e-12, 6.25e-12, 1.25e-11, 6.25e-12], "cur_lr": 0.001, "total_loss": 36.66497802734375, "policy_loss": 0.0003333072236273438, "vf_loss": 73.33062744140625, "kl_loss": 0.001874839887022972, "inner_kl": [0.0018500173464417458, 0.001765616936609149, 0.0019031858537346125, 0.0020096662919968367], "entropy": 0.4466087222099304}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32000}}, "num_steps_trained_this_iter": 32000, "num_steps_trained": 480000, "num_steps_sampled": 8021}, "MAMLIter0_DynaTrajInner_0_episode_reward_mean": 20.05, "MAMLIter0_DynaTrajInner_0_episode_reward_min": 7.0, "MAMLIter0_DynaTrajInner_0_episode_reward_max": 57.0, "MAMLIter0_DynaTrajInner_1_episode_reward_mean": 22.3875, "MAMLIter0_DynaTrajInner_1_episode_reward_min": 8.0, "MAMLIter0_DynaTrajInner_1_episode_reward_max": 82.0, "MAMLIter1_DynaTrajInner_0_episode_reward_mean": 23.3625, "MAMLIter1_DynaTrajInner_0_episode_reward_min": 9.0, "MAMLIter1_DynaTrajInner_0_episode_reward_max": 73.0, "MAMLIter1_DynaTrajInner_1_episode_reward_mean": 24.375, "MAMLIter1_DynaTrajInner_1_episode_reward_min": 8.0, "MAMLIter1_DynaTrajInner_1_episode_reward_max": 87.0, "MAMLIter2_DynaTrajInner_0_episode_reward_mean": 25.2, "MAMLIter2_DynaTrajInner_0_episode_reward_min": 7.0, "MAMLIter2_DynaTrajInner_0_episode_reward_max": 78.0, "MAMLIter2_DynaTrajInner_1_episode_reward_mean": 27.5625, "MAMLIter2_DynaTrajInner_1_episode_reward_min": 8.0, "MAMLIter2_DynaTrajInner_1_episode_reward_max": 78.0, "MAMLIter3_DynaTrajInner_0_episode_reward_mean": 28.1625, "MAMLIter3_DynaTrajInner_0_episode_reward_min": 9.0, "MAMLIter3_DynaTrajInner_0_episode_reward_max": 79.0, "MAMLIter3_DynaTrajInner_1_episode_reward_mean": 27.4125, "MAMLIter3_DynaTrajInner_1_episode_reward_min": 9.0, "MAMLIter3_DynaTrajInner_1_episode_reward_max": 108.0, "MAMLIter4_DynaTrajInner_0_episode_reward_mean": 35.3875, "MAMLIter4_DynaTrajInner_0_episode_reward_min": 11.0, "MAMLIter4_DynaTrajInner_0_episode_reward_max": 82.0, "MAMLIter4_DynaTrajInner_1_episode_reward_mean": 27.7875, "MAMLIter4_DynaTrajInner_1_episode_reward_min": 8.0, "MAMLIter4_DynaTrajInner_1_episode_reward_max": 82.0, "MAMLIter5_DynaTrajInner_0_episode_reward_mean": 33.675, "MAMLIter5_DynaTrajInner_0_episode_reward_min": 9.0, "MAMLIter5_DynaTrajInner_0_episode_reward_max": 156.0, "MAMLIter5_DynaTrajInner_1_episode_reward_mean": 29.375, "MAMLIter5_DynaTrajInner_1_episode_reward_min": 10.0, "MAMLIter5_DynaTrajInner_1_episode_reward_max": 118.0, "MAMLIter6_DynaTrajInner_0_episode_reward_mean": 34.7625, "MAMLIter6_DynaTrajInner_0_episode_reward_min": 9.0, "MAMLIter6_DynaTrajInner_0_episode_reward_max": 140.0, "MAMLIter6_DynaTrajInner_1_episode_reward_mean": 36.5625, "MAMLIter6_DynaTrajInner_1_episode_reward_min": 8.0, "MAMLIter6_DynaTrajInner_1_episode_reward_max": 137.0, "MAMLIter7_DynaTrajInner_0_episode_reward_mean": 35.575, "MAMLIter7_DynaTrajInner_0_episode_reward_min": 10.0, "MAMLIter7_DynaTrajInner_0_episode_reward_max": 114.0, "MAMLIter7_DynaTrajInner_1_episode_reward_mean": 36.6125, "MAMLIter7_DynaTrajInner_1_episode_reward_min": 9.0, "MAMLIter7_DynaTrajInner_1_episode_reward_max": 127.0, "MAMLIter8_DynaTrajInner_0_episode_reward_mean": 31.325, "MAMLIter8_DynaTrajInner_0_episode_reward_min": 8.0, "MAMLIter8_DynaTrajInner_0_episode_reward_max": 134.0, "MAMLIter8_DynaTrajInner_1_episode_reward_mean": 36.15, "MAMLIter8_DynaTrajInner_1_episode_reward_min": 8.0, "MAMLIter8_DynaTrajInner_1_episode_reward_max": 95.0, "MAMLIter9_DynaTrajInner_0_episode_reward_mean": 34.725, "MAMLIter9_DynaTrajInner_0_episode_reward_min": 8.0, "MAMLIter9_DynaTrajInner_0_episode_reward_max": 106.0, "MAMLIter9_DynaTrajInner_1_episode_reward_mean": 32.8625, "MAMLIter9_DynaTrajInner_1_episode_reward_min": 11.0, "MAMLIter9_DynaTrajInner_1_episode_reward_max": 154.0, "MAMLIter10_DynaTrajInner_0_episode_reward_mean": 31.6875, "MAMLIter10_DynaTrajInner_0_episode_reward_min": 9.0, "MAMLIter10_DynaTrajInner_0_episode_reward_max": 94.0, "MAMLIter10_DynaTrajInner_1_episode_reward_mean": 32.2375, "MAMLIter10_DynaTrajInner_1_episode_reward_min": 9.0, "MAMLIter10_DynaTrajInner_1_episode_reward_max": 74.0, "MAMLIter11_DynaTrajInner_0_episode_reward_mean": 29.5, "MAMLIter11_DynaTrajInner_0_episode_reward_min": 10.0, "MAMLIter11_DynaTrajInner_0_episode_reward_max": 113.0, "MAMLIter11_DynaTrajInner_1_episode_reward_mean": 39.375, "MAMLIter11_DynaTrajInner_1_episode_reward_min": 10.0, "MAMLIter11_DynaTrajInner_1_episode_reward_max": 135.0, "MAMLIter12_DynaTrajInner_0_episode_reward_mean": 34.1625, "MAMLIter12_DynaTrajInner_0_episode_reward_min": 9.0, "MAMLIter12_DynaTrajInner_0_episode_reward_max": 93.0, "MAMLIter12_DynaTrajInner_1_episode_reward_mean": 32.6375, "MAMLIter12_DynaTrajInner_1_episode_reward_min": 10.0, "MAMLIter12_DynaTrajInner_1_episode_reward_max": 91.0, "MAMLIter13_DynaTrajInner_0_episode_reward_mean": 38.7, "MAMLIter13_DynaTrajInner_0_episode_reward_min": 10.0, "MAMLIter13_DynaTrajInner_0_episode_reward_max": 135.0, "MAMLIter13_DynaTrajInner_1_episode_reward_mean": 36.9375, "MAMLIter13_DynaTrajInner_1_episode_reward_min": 8.0, "MAMLIter13_DynaTrajInner_1_episode_reward_max": 100.0, "MAMLIter14_DynaTrajInner_0_episode_reward_mean": 37.475, "MAMLIter14_DynaTrajInner_0_episode_reward_min": 12.0, "MAMLIter14_DynaTrajInner_0_episode_reward_max": 141.0, "MAMLIter14_DynaTrajInner_1_episode_reward_mean": 41.6, "MAMLIter14_DynaTrajInner_1_episode_reward_min": 10.0, "MAMLIter14_DynaTrajInner_1_episode_reward_max": 171.0, "num_recreated_workers": 0, "done": false, "episodes_total": 143, "training_iteration": 1, "trial_id": "9ab5b_00000", "experiment_id": "775ef261926f4af6a46685a52e52b9d6", "date": "2022-08-20_13-12-50", "timestamp": 1660981370, "time_this_iter_s": 206.82311630249023, "time_total_s": 206.82311630249023, "pid": 20887, "hostname": "ajit-hp", "node_ip": "192.168.18.179", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "myenv", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 4, "num_envs_per_worker": 20, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": 200, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [32, 32], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": true, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "<class 'ray.rllib.algorithms.mbmpo.utils.MBMPOExploration'>", "random_timesteps": 8000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "myenv", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 4, "num_envs_per_worker": 20, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 200, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": 200, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [32, 32], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": true, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "<class 'ray.rllib.algorithms.mbmpo.utils.MBMPOExploration'>", "random_timesteps": 8000}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "use_gae": true, "kl_coeff": 1e-10, "vf_loss_coeff": 0.5, "entropy_coeff": 0.0, "clip_param": 0.5, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.003, "inner_adaptation_steps": 1, "maml_optimizer_steps": 8, "inner_lr": 0.001, "dynamics_model": {"custom_model": "<class 'ray.rllib.algorithms.mbmpo.model_ensemble.DynamicsEnsembleCustomModel'>", "ensemble_size": 5, "fcnet_hiddens": [512, 512, 512], "lr": 0.001, "train_epochs": 500, "batch_size": 500, "valid_split_ratio": 0.2, "normalize_data": true}, "custom_vector_env": "<function model_vector_env at 0x7f19ade24c10>", "num_maml_steps": 15, "vf_share_layers": -1, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7f19adb6ec10>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": true, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "use_gae": true, "kl_coeff": 1e-10, "vf_loss_coeff": 0.5, "entropy_coeff": 0.0, "clip_param": 0.5, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.003, "inner_adaptation_steps": 1, "maml_optimizer_steps": 8, "inner_lr": 0.001, "dynamics_model": {"custom_model": "<class 'ray.rllib.algorithms.mbmpo.model_ensemble.DynamicsEnsembleCustomModel'>", "ensemble_size": 5, "fcnet_hiddens": [512, 512, 512], "lr": 0.001, "train_epochs": 500, "batch_size": 500, "valid_split_ratio": 0.2, "normalize_data": true}, "custom_vector_env": "<function model_vector_env at 0x7f19ade24c10>", "num_maml_steps": 15, "vf_share_layers": -1, "lambda": 1.0, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7f19adb6eee0>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": true, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1}, "time_since_restore": 206.82311630249023, "timesteps_since_restore": 32000, "iterations_since_restore": 1, "warmup_time": 256.43239164352417, "perf": {"cpu_util_percent": 39.04761904761905, "ram_util_percent": 42.41122448979591}}
